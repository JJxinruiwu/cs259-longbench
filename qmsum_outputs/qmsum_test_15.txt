Professor B: I think for two years we were two months, uh, away from being done.
PhD A: And what was that, Morgan? What project?
Professor B: Uh, the, uh, TORRENT chip.
PhD A: Oh.
Professor B: Yeah. We were two {disfmarker} we were {disfmarker}
PhD C: Yeah.
Professor B: Uh, uh, we went through it {disfmarker} Jim and I went through old emails at one point and {disfmarker} and for two years there was this thing saying, yeah, we're {disfmarker} we're two months away from being done. It was very {disfmarker} very believable schedules, too. I mean, we went through and {disfmarker} with the schedules {disfmarker} and we {disfmarker}
PhD A: It was true for two years.
Professor B: Yeah. Oh, yeah. It was very true.
PhD A: So, should we just do the same kind of deal where we {pause} go around and do, uh, status report {pause} kind of things? OK. And I guess when Sunil gets here he can do his last or something. So.
Professor B: Yeah. So we {pause} probably should wait for him to come before we do his.
PhD C: Mm - hmm.
PhD A: OK. That's a good idea.
Professor B: Yeah.
Grad F: OK.
Professor B: Yeah.
PhD A: Any objection? Do y OK, M
Professor B: All in favor
PhD A: Do you want to start, Morgan? Do you have anything, or {disfmarker}?
Professor B: Uh, I don't do anything. I {disfmarker} No, I mean, I {disfmarker} I'm involved in discussions with {disfmarker} with people about what they're doing, but I think they're {disfmarker} since they're here, they can talk about it themselves.
Grad F: OK. So should I go so that, uh,
PhD A: Yeah. Why don't you go ahead, Barry?
Grad F: you're gonna talk about Aurora stuff, per se?
PhD A: OK.
Grad F: OK. Um. Well, this past week I've just been, uh, getting down and dirty into writing my {disfmarker} my proposal. So, um {disfmarker} Mmm. I just finished a section on, uh {disfmarker} on talking about these intermediate categories that I want to classify, um, as a {disfmarker} as a middle step. And, um, I hope to {disfmarker} hope to get this, um {disfmarker} a full rough draft done by, uh, Monday so I can give it to Morgan.
PhD A: When is your, uh, meeting?
Grad F: Um, my meeting
PhD A: Yeah.
Grad F: with, uh {disfmarker}? Oh, oh, you mean the {disfmarker} the quals.
PhD A: The quals. Yeah.
Grad F: Uh, the quals are happening in July twenty - fifth.
PhD A: Oh. Soon.
Grad F: Yeah.
PhD A: Uh - huh.
Grad F: D - Day.
PhD A: Yeah.
Grad F: Uh - huh.
PhD A: So, is the idea you're going to do this paper and then you pass it out to everybody ahead of time and {disfmarker}?
Grad F: Right, right. So, y you write up a proposal, and give it to people ahead of time, and you have a short presentation. And, um, and then, um {disfmarker} then everybody asks you questions.
PhD A: Hmm.
Grad F: Yeah.
PhD A: I remember now.
Grad F: Yep. So, um.
PhD A: Have you d? I was just gonna ask, do you want to say any {disfmarker} a little bit about it,
Grad F: Y s
PhD A: or {disfmarker}? Mmm.
Grad F: Oh. Uh, a little bit about {disfmarker}?
PhD A: Wh - what you're {disfmarker} what you're gonna {disfmarker} You said {disfmarker} you were talking about the, uh, particular features that you were looking at,
Grad F: Oh, the {disfmarker} the {disfmarker}
PhD A: or {disfmarker}
Grad F: Right. Well, I was, um, I think one of the perplexing problems is, um, for a while I was thinking that I had to come up with a complete set of intermediate features {disfmarker} in intermediate categories to {disfmarker} to classify right away. But what I'm thinking now is, I would start with {disfmarker} with a reasonable set. Something {disfmarker} something like, um, um {disfmarker} like, uh, re regular phonetic features, just to {disfmarker} just to start off that way. And do some phone recognition. Um, build a system that, uh, classifies these, um {disfmarker} these feat uh, these intermediate categories using, uh, multi - band techniques. Combine them and do phon phoneme recognition. Look at {disfmarker} then I would look at the errors produced in the phoneme recognition and say, OK, well, I could probably reduce the errors if I included this extra feature or this extra intermediate category. That would {disfmarker} that would reduce certain confusions over other confusions. And then {disfmarker} and then {vocalsound} reiterate. Um, build the intermediate classifiers. Uh, do phoneme recognition. Look at the errors. And then postulate new {disfmarker} or remove, um, intermediate categories. And then do it again.
PhD A: So you're gonna use TIMIT?
Grad F: Um, for that {disfmarker} for that part of the {disfmarker} the process, yeah, I would use TIMIT.
PhD A: Mm - hmm.
Grad F: And, um, then {disfmarker} after {disfmarker} after, uh, um, doing TIMIT. Right?
PhD A: Mm - hmm.
Grad F: Um, that's {disfmarker} {vocalsound} that's, um {disfmarker} that's just the ph the phone recognition task.
PhD A: Yeah.
Grad F: Uh, I wanted to take a look at, um, things that I could model within word. So, I would mov I would then shift the focus to, um, something like Schw - Switchboard, uh, where I 'd {disfmarker} I would be able to, um {disfmarker} to model, um, intermediate categories that span across phonemes,
PhD A: Mm - hmm.
Grad F: not just within the phonemes, themselves, um, and then do the same process there, um, on {disfmarker} on a large vocabulary task like Switchboard. Uh, and for that {disfmarker} for that part I would {disfmarker} I 'd use the SRI recognizer since it's already set up for {disfmarker} for Switchboard. And I 'd run some {disfmarker} some sort of tandem - style processing with, uh, my intermediate classifiers.
PhD A: Oh. So that's why you were interested in getting your own features into the SRI files.
Grad F: Yeah. That's why I {disfmarker} I was asking about that.
PhD A: Yeah. Yeah.
Grad F: Yeah. Um, and I guess that's {disfmarker} that's it. Any {disfmarker} any questions?
PhD A: Sounds good. So you just have a few more weeks, huh?
Grad F: Um, yeah. A few more.
PhD A: It's about a month from now?
Grad F: It's a {disfmarker} it's a month and {disfmarker} and a week.
PhD A: Yeah.
Grad F: Yeah.
PhD A: So, uh, you want to go next, Dave? And we 'll do {disfmarker}
Grad E: Oh. OK, sure. So, um, last week I finally got results from the SRI system about this mean subtraction approach. And, um, we {disfmarker} we got an improvement, uh, in word error rate, training on the TI - digits data set and testing on Meeting Recorder digits of, um, {vocalsound} six percent to four point five percent, um, on the n on the far - mike data using PZM F, but, um, the near - mike performance worsened, um, from one point two percent to two point four percent. And, um, wh why would that be, um, {vocalsound} considering that we actually got an improvement in near - mike performance using HTK? And so, uh, with some input from, uh, Andreas, I have a theory in two parts. Um, first of all HTK {disfmarker} sorry, SR - the SRI system is doing channel adaptation, and so HTK wasn't. Um, so this, um {disfmarker} This mean subtraction approach will do a kind of channel {pause} normalization and so that might have given the HTK use of it a boost that wouldn't have been applied in the SRI case. And also, um, the {disfmarker} Andreas pointed out the SRI system is using more parameters. It's got finer - grained acoustic models. So those finer - grained acoustic models could be more sensitive to the artifacts {pause} in the re - synthesized audio. Um. And me and Barry were listening to the re - synthesized audio and sometimes it seems like you get of a bit of an echo of speech in the background. And so that seems like it could be difficult for training, cuz you could have {pause} different phones {pause} lined up with a different foreground phone, {vocalsound} um, {vocalsound} depending on {pause} the timing of the echo. So, um, I'm gonna try training on a larger data set, and then, eh, the system will have seen more examples o of these artifacts and hopefully will be more robust to them. So I'm planning to use the Macrophone set of, um, read speech, and, um {disfmarker} Hmm.
Professor B: I had another thought just now, which is, uh, remember we were talking before about {disfmarker} we were talking in our meeting about, uh, this stuff that {disfmarker} some of the other stuff that Avendano did, where they were, um, getting rid of low - energy {pause} sections? Um, uh, if you {disfmarker} if you did a high - pass filtering, as Hirsch did in {pause} late eighties to reduce some of the effects of reverberation, uh, uh, Avendano and Hermansky were arguing that, uh, perhaps one of the reasons for that working was ma may not have even been the filtering so much but the fact that when you filter a {disfmarker} an all - positive power spectrum you get some negative values, and you gotta figure out what to do with them if you're gonna continue treating this as a power spectrum. So, what {disfmarker} what Hirsch did was, uh, set them to zero {disfmarker} set the negative values to zero. So if you imagine a {disfmarker} a waveform that's all positive, which is the time trajectory of energy, um, and, uh, shifting it downwards, and then getting rid of the negative parts, that's essentially throwing away the low - energy things. And it's the low - energy parts of the speech where the reverberation is most audible. You know, you have the reverberation from higher - energy things showing up in {disfmarker} So in this case you have some artificially imposed {pause} reverberation - like thing. I mean, you're getting rid of some of the other effects of reverberation, but because you have these non - causal windows, you're getting these funny things coming in, uh, at n And, um, what if you did {disfmarker}? I mean, there's nothing to say that the {disfmarker} the processing for this re - synthesis has to be restricted to trying to get it back to the original, according to some equation. I mean, you also could, uh, just try to make it nicer.
Grad E: Uh - huh.
Professor B: And one of the things you could do is, you could do some sort of VAD - like thing
Grad E: Mm - hmm.
Professor B: and you actually could take very low - energy sections and set them to some {disfmarker} some, uh, very low or {disfmarker} or near zero {pause} value. I mean, uh, I'm just saying if in fact it turns out that {disfmarker} that these echoes that you're hearing are, uh {disfmarker}
Grad E: Uh - huh.
Professor B: or pre - echoes, whichever they are {disfmarker} are {disfmarker} are, uh, part of what's causing the problem, you actually could get rid of them.
Grad E: Uh - huh.
Professor B: Be pretty simple. I mean, you do it in a pretty conservative way
Grad E: OK.
Professor B: so that if you made a mistake you were more likely to {pause} keep in an echo than to throw out speech.
Grad E: Hmm.
PhD G: Um, what is the reverberation time {pause} like {pause} there?
Grad E: In thi in this room? Uh {disfmarker}
PhD G: On, uh, the {disfmarker} the one what {disfmarker} the s in the speech that you are {disfmarker} you are using like?
Grad E: Y Yeah. I {disfmarker} I {disfmarker} I {disfmarker} I don't know.
Professor B: So, it's this room.
PhD G: It's, uh {disfmarker}
Professor B: It's {disfmarker} it's this room.
PhD G: Oh, this room?
Professor B: So {disfmarker}
PhD G: OK.
Professor B: so it's {disfmarker} these are just microphone {disfmarker} this micro close microphone and a distant microphone, he's doing these different tests on.
Grad F: Oh.
Professor B: Uh, we should do a measurement in here. I g think we never have. I think it's {disfmarker} I would guess, uh, point seven, point eight seconds f uh, R T
Grad F: Hmm!
Professor B: something like that? But it's {disfmarker} you know, it's this room.
PhD G: Mm - hmm.
Professor B: So.
PhD G: OK. Mm - hmm.
Professor B: Uh. But the other thing is, he's putting in {disfmarker} w I was using the word " reverberation " in two ways. He's also putting in, uh, a {disfmarker} he's taking out some reverberation, but he's putting in something, because he has {pause} averages over multiple windows stretching out to twelve seconds, which are then being subtracted from the speech. And since, you know, what you subtract, sometimes you 'll be {disfmarker} you 'll be subtracting from some larger number and sometimes you won't. And {disfmarker}
PhD G: Mm - hmm. Mm - hmm.
Professor B: So you can end up with some components in it that are affected by things that are seconds away. Uh, and if it's a low {pause} energy compo portion, you might actually hear some {pause} funny things.
PhD G: Yeah.
Grad E: O o one thing, um, I noticed is that, um, the mean subtraction seems to make the PZM signals louder after they've been re - synthesized. So I was wondering, is it possible that one reason it helped with the Aurora baseline system is {pause} just as a kind of gain control? Cuz some of the PZM signals sound pretty quiet if you don't amplify them.
PhD C: Mm - hmm. I don't see why {disfmarker} why your signal is louder after processing, because yo
Grad E: Yeah. I don't know why - y, uh, either.
PhD C: Yeah.
Professor B: I don't think just multiplying the signal by two would have any effect.
PhD C: Mm - hmm.
Grad E: Oh, OK.
Professor B: Yeah. I mean, I think if you really have louder signals, what you mean is that you have {pause} better signal - to - noise ratio.
PhD C: Well, well {disfmarker}
Professor B: So if what you're doing is improving the signal - to - noise ratio, then it would be better.
PhD C: Mm - hmm.
Professor B: But just it being bigger if {disfmarker} with the same signal - to - noise ratio {disfmarker}
Grad E: It w i i it wouldn't affect things.
Professor B: No.
PhD C: Yeah.
Grad E: OK.
PhD C: Well, the system is {disfmarker} use {pause} the absolute energy, so it's a little bit dependent on {disfmarker} on the {pause} signal level. But, not so much, I guess.
Professor B: Well, yeah. But it's trained and tested on the same thing.
PhD C: Mmm.
Professor B: So if the {disfmarker} if the {disfmarker} if you change {vocalsound} in both training and test, the absolute level by a factor of two, it will n have no effect.
PhD C: Mm - hmm. Yeah.
PhD A: Did you add {pause} this data to the training set, for the Aurora? Or you just tested on this?
Grad E: Uh {disfmarker} Um. Did I w what?
PhD A: Well, Morgan was just saying that, uh, as long as you do it in both training and testing, it shouldn't have any effect.
Grad E: Sorry? Yeah.
PhD A: But I {disfmarker} I was {pause} sort of under the impression that you had done it, and I was wondering if it was the same thing. So.
Grad E: Yeah.
PhD A: So, just to be clear, you {disfmarker} you did it, and it shouldn't have any effect.
Grad E: Yeah.
PhD A: That's good to know. So, uh, now that we have this data, we can try to {pause} apply it to the Aurora system, and see if it makes any difference.
Grad E: Uh {disfmarker} Mm - hmm.
Professor B: Yeah. And we should do a comparison of the {disfmarker} the results of the two systems. So.
Grad E: Yeah.
PhD A: So, uh, we can compare the {disfmarker} the performance of the two systems, and see if the addition of this data makes any difference. So.
Grad E: Yeah.
Professor B: Yeah. And that's a good idea